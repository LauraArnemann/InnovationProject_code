{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93810350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This python file cleans the NETS data for matching \n",
    "import pandas as pd\n",
    "# Opening the data set in chunks and also preparing it in chunks because I don't have sufficient memory\n",
    "# The following steps carry out the equivalent to a reshape command in stata and \n",
    "#eliminate duplicate fips and dunsnumber observations in the last step we match this with commuting zone information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cb379ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years 1990 until 2000\n",
    "columns_to_keep = [\"dunsnumber\", \"fips90\", \"fips91\", \"fips92\", \"fips93\", \"fips94\", \"fips95\", \"fips96\", \"fips97\", \"fips98\", \"fips99\"]\n",
    "df3 = pd.read_stata('H:/data/2022_NETS_database/NETS2022_Misc/fips.dta', columns=columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(90, 100):\n",
    "    column_name = f'fips{i}'\n",
    "    df_name = f'df3_{i}'  # Construct the DataFrame name as a string\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df3[['dunsnumber', column_name]].copy()\n",
    "    df_filtered = df_filtered[df_filtered[column_name].notna()]\n",
    "    df_filtered = df_filtered.rename(columns={column_name: 'fips'})\n",
    "    \n",
    "    # Dynamically create a variable with exec()\n",
    "    exec(f\"{df_name} = df_filtered\")\n",
    "\n",
    "# Combining the data frames     \n",
    "combined_df1 = pd.concat([df3_90, df3_91, df3_92, df3_93, df3_94, df3_95, df3_96, df3_97, df3_98, df3_99])\n",
    "\n",
    "del_df=[df3_90, df3_91, df3_92, df3_93, df3_94, df3_95, df3_96, df3_97, df3_98, df3_99]\n",
    "\n",
    "for i in del_df: \n",
    "    del (i)\n",
    "\n",
    "# Remove Duplicates of FIPS and Commuting Zone\n",
    "duplicates = combined_df1.duplicated(subset=['dunsnumber', 'fips'], keep=False)\n",
    "combined_df1 = combined_df1[~duplicates]\n",
    "combined_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18c1643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years 2000 until 2010\n",
    "columns_to_keep = [\"dunsnumber\", \"fips00\", \"fips01\", \"fips02\", \"fips03\", \"fips04\", \"fips05\", \"fips06\", \"fips07\", \"fips08\", \"fips09\"]\n",
    "df3 = pd.read_stata('H:/data/2022_NETS_database/NETS2022_Misc/fips.dta', columns=columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7775864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunsnumber</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1000702</td>\n",
       "      <td>25009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1000769</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1000785</td>\n",
       "      <td>25025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1001072</td>\n",
       "      <td>25021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1002575</td>\n",
       "      <td>25025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dunsnumber     fips\n",
       "86      1000702  25009.0\n",
       "98      1000769  39061.0\n",
       "101     1000785  25025.0\n",
       "136     1001072  25021.0\n",
       "322     1002575  25025.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    column_name = f'fips0{i}'\n",
    "    df_name = f'df3_{i}'  # Construct the DataFrame name as a string\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df3[['dunsnumber', column_name]].copy()\n",
    "    df_filtered = df_filtered[df_filtered[column_name].notna()]\n",
    "    df_filtered = df_filtered.rename(columns={column_name: 'fips'})\n",
    "    \n",
    "    # Dynamically create a variable with exec()\n",
    "    exec(f\"{df_name} = df_filtered\")\n",
    "\n",
    "\n",
    "# Combining the data frames     \n",
    "combined_df2 = pd.concat([df3_0, df3_1, df3_2, df3_3, df3_4, df3_5, df3_6, df3_7, df3_8, df3_9])\n",
    "del_df=[df3_0, df3_1, df3_2, df3_3, df3_4, df3_5, df3_6, df3_7, df3_8, df3_9]\n",
    "\n",
    "for i in del_df: \n",
    "    del (i)\n",
    "\n",
    "# Remove Duplicates of FIPS and Commuting Zone\n",
    "duplicates = combined_df2.duplicated(subset=['dunsnumber', 'fips'], keep=False)\n",
    "combined_df2 = combined_df2[~duplicates]\n",
    "combined_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d8a3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years 2010 until 2022\n",
    "columns_to_keep = [\"dunsnumber\", \"fips10\", \"fips11\", \"fips12\", \"fips13\", \"fips14\", \"fips15\", \"fips16\", \"fips17\", \"fips18\", \"fips19\", \"fips20\", \"fips21\", \"fips22\"]\n",
    "df3 = pd.read_stata('H:/data/2022_NETS_database/NETS2022_Misc/fips.dta', columns=columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b271732d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_16044\\835600087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Remove Duplicates of FIPS and Commuting Zone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mduplicates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_df3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dunsnumber'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mcombined_df3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_df3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mcombined_df3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_df3' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10, 23):\n",
    "    column_name = f'fips{i}'\n",
    "    df_name = f'df3_{i}'  # Construct the DataFrame name as a string\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df3[['dunsnumber', column_name]].copy()\n",
    "    df_filtered = df_filtered[df_filtered[column_name].notna()]\n",
    "    df_filtered = df_filtered.rename(columns={column_name: 'FIPS'})\n",
    "    \n",
    "    # Dynamically create a variable with exec()\n",
    "    exec(f\"{df_name} = df_filtered\")\n",
    "    \n",
    "\n",
    "# Combining the data frames     \n",
    "combined_df3 = pd.concat([df3_10, df3_11, df3_12, df3_13, df3_14, df3_15, df3_16, df3_17, df3_18, df3_19, df3_20, df3_21, df3_22])\n",
    "del_df=[df3_10, df3_11, df3_12, df3_13, df3_14, df3_15, df3_16, df3_17, df3_18, df3_19, df3_20, df3_21, df3_22]\n",
    "\n",
    "for i in del_df: \n",
    "    del (i)\n",
    "\n",
    "# Remove Duplicates of FIPS and Commuting Zone\n",
    "duplicates = combined_df3.duplicated(subset=['dunsnumber', 'fips'], keep=False)\n",
    "combined_df3 = combined_df3[~duplicates]\n",
    "combined_df3.head()\n",
    "\n",
    "\n",
    "# Combine all three data sets\n",
    "combined_df = pd.concat([combined_df1, combined_df2, combined_df3])\n",
    "\n",
    "del combined_df1 \n",
    "del combined_df2 \n",
    "del combined_df3\n",
    "\n",
    "# Removing duplicates again \n",
    "duplicates = combined_df.duplicated(subset=['dunsnumber', 'fips'], keep=False)\n",
    "combined_df = combined_df[~duplicates]\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b90421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set with the commuting zones merging in commuting zones\n",
    "df4 = pd.read_stata('H:/InnovationProject/data/raw/var_CommutingZones/CZ_combined.dta')\n",
    "df4 = df4[['county_fips', 'CZ_depagri_1990']]\n",
    "df4.head()\n",
    "\n",
    "combined_df = pd.merge(combined_df, df4, left_on='FIPS', right_on='county_fips')\n",
    "\n",
    "# Only keep non-duplicates in terms of commuting zone and \n",
    "duplicates = combined_df.duplicated(subset=['DunsNumber', 'CZ_depagri_1990'], keep=False)\n",
    "combined_df = combined_df[~duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1125d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge this with the remainder of the NETS data (cleaned owners) and hqs\n",
    "df1 = pd.read_stata('H:/InnovationProject/data/temp/cleaned_owners.dta')\n",
    "df2 = pd.read_stata('H:/InnovationProject/data/temp/hqs.dta')\n",
    "\n",
    "# Cleaning the data \n",
    "df2 = df2.drop_duplicates(subset=['hqduns', 'hqcompany', 'hqtradename'])\n",
    "df2 = df2[['hqduns', 'hqcompany', 'hqtradename']]\n",
    "merged_df = pd.merge(df1, df2, on=['hqduns'])\n",
    "merged_df = pd.merge(combined_df, merged_df, on=['dunsnumber'])\n",
    "\n",
    "# Checking the merge \n",
    "merged_df.head()\n",
    "merged_df = merged_df[['dunsnumber', 'CZ_depagri_1990','hqduns', 'hqcompany', 'hqtradename']]\n",
    "\n",
    "# Export the data\n",
    "merged_df.to_stata('H:/InnovationProject/data/temp/NETS_prep.dta', write_index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
