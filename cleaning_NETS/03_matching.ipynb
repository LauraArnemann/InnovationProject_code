{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aab329d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages \n",
    "#!pip3 install python-Levenshtein --user\n",
    "#!pip3 install fuzzywuzzy --user\n",
    "\n",
    "import fuzzywuzzy\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a79707b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the prepared NETS data set \n",
    "df1 = pd.read_stata('H:/InnovationProject/data/temp/NETS_prep.dta') \n",
    "df1['hqcompany'] = df1['hqcompany'].str.strip().str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df1['hqtradename'] = df1['hqtradename'].str.strip().str.lower().str.replace(r'[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88f3a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing information to match counties to commuting zones \n",
    "df4 = pd.read_stata('H:/InnovationProject/data/raw/var_CommutingZones/CZ_combined.dta')\n",
    "df4 = df4[['county_fips', 'CZ_depagri_1990']]\n",
    "\n",
    "length1 = 5\n",
    "df4['county_fips'] = df4['county_fips'].astype(str).str.zfill(length1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb91dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the inventor data set, only keeping the necessary information and merging in commuting zones \n",
    "df2 = pd.read_stata('H:/InnovationProject/data/temp/patentdata_clean_assignee.dta')\n",
    "\n",
    "length1 = 2\n",
    "length2 = 3\n",
    "\n",
    "# Fill var1 and var2 with leading zeros and combine them\n",
    "df2['combined_var'] = df2['state_fips_inventor'].astype(str).str.zfill(length1) + df2['county_fips_inventor'].astype(str).str.zfill(length2)\n",
    "df2 = df2.rename(columns={'combined_var': 'county_fips'})\n",
    "df2 =df2[['assignee_id', 'assignee_std', 'gvkey', 'county_fips']]\n",
    "\n",
    "df2 = pd.merge(df4, df2, on=['county_fips'])\n",
    "\n",
    "df2 = df2[['assignee_id', 'assignee_std', 'CZ_depagri_1990']]\n",
    "df2 = df2.drop_duplicates(subset=['assignee_id', 'CZ_depagri_1990'])\n",
    "df2['assignee_std'] = df2['assignee_std'].str.strip().str.lower().str.replace(r'[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "430efc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19600.0\n",
      "H:/InnovationProject/data/temp/matching_NETS/match_19600.0.csv\n",
      "H:/InnovationProject/data/temp/matching_NETS/nonmatch_NETS_19600.0.csv\n",
      "H:/InnovationProject/data/temp/matching_NETS/nonmatch_patents_19600.0.csv\n"
     ]
    }
   ],
   "source": [
    "# Merging both data sets together based on direct matching \n",
    "# Writing the function for fuzzy matching\n",
    "def match_names(row, df2_filtered, threshold=90):\n",
    "    name = row['hqcompany']\n",
    "    matches = process.extractOne(name, df2_filtered['hqcompany'], scorer=fuzz.token_sort_ratio)\n",
    "    if matches[1] >= threshold:\n",
    "        return matches[0]\n",
    "    return None\n",
    "\n",
    "for value in df2['CZ_depagri_1990'].unique():     \n",
    "    print(value)\n",
    "    df2_subset = df2[df2['CZ_depagri_1990'] == value]\n",
    "    df1_subset = df1[df1['CZ_depagri_1990'] == value ]\n",
    "    df2_subset = df2_subset.rename(columns={'assignee_std': 'hqcompany'})\n",
    "    matched1 = pd.merge(df1_subset, df2_subset, on=['hqcompany', 'CZ_depagri_1990'], how='inner')\n",
    "    \n",
    "    # Identify direct matches and delete them; for both data sets\n",
    "    df1_filtered = df1_subset.merge(matched1, on=['hqcompany'], how='left', indicator=True)\n",
    "    df1_filtered = df1_filtered[df1_filtered['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "    \n",
    "    df2_filtered = df2_subset.merge(matched1, on=['hqcompany'], how='left', indicator=True)\n",
    "    df2_filtered = df2_filtered[df2_filtered['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "    \n",
    "    # Renaming the matched variables  \n",
    "    df2_filtered = df2_filtered[['assignee_id_x', 'hqcompany', 'CZ_depagri_1990_x']]\n",
    "    df2_filtered = df2_filtered.rename(columns={'assignee_id_x': 'assignee_id'})\n",
    "    df2_filtered = df2_filtered.rename(columns={'CZ_depagri_1990_x': 'CZ_depagri_1990'})\n",
    "    \n",
    "    df1_filtered = df1_filtered[['dunsnumber_x', 'hqduns_x', 'hqcompany', 'hqtradename_x', 'CZ_depagri_1990_x']]\n",
    "    df1_filtered = df1_filtered.rename(columns={'dunsnumber_x': 'dunsnumber'})\n",
    "    df1_filtered = df1_filtered.rename(columns={'hqtradename_x': 'hqtradename'})\n",
    "    df1_filtered = df1_filtered.rename(columns={'hqduns_x': 'hqduns'})\n",
    "    df1_filtered = df1_filtered.rename(columns={'CZ_depagri_1990_x': 'CZ_depagri_1990'})\n",
    "    \n",
    "    # Step 2: Fuzzy Matching\n",
    "    df1_filtered['matched_name'] = df1_filtered.apply(match_names, axis=1, df2_filtered=df2_filtered)\n",
    "    df1_filtered = df1_filtered.rename(columns={'hqcompany': 'original_name'})\n",
    "    df1_filtered = df1_filtered.rename(columns={'matched_name': 'hqcompany'})\n",
    "    df1_filtered = df1_filtered.dropna(subset=['hqcompany'])\n",
    "    matched2 = pd.merge(df2_filtered, df1_filtered, on=['hqcompany', 'CZ_depagri_1990'], how='inner')\n",
    "    \n",
    "    df_combined = pd.concat([matched1, matched2], ignore_index=True)\n",
    "    \n",
    "    # Define, dynamic file path \n",
    "    file_path = f\"H:/InnovationProject/data/temp/matching_NETS/match_{value}.csv\"\n",
    "    df_combined.to_csv(file_path) \n",
    "    \n",
    "    df1_cleaned = df1_filtered.applymap(lambda x: x.encode('latin-1', 'replace').decode('latin-1') if isinstance(x, str) else x)\n",
    "    df2_cleaned = df2_filtered.applymap(lambda x: x.encode('latin-1', 'replace').decode('latin-1') if isinstance(x, str) else x)\n",
    "    \n",
    "    file_path = f\"H:/InnovationProject/data/temp/matching_NETS/nonmatch_NETS_{value}.csv\"\n",
    "    df1_cleaned.to_stata(file_path) \n",
    "    \n",
    "    file_path = f\"H:/InnovationProject/data/temp/matching_NETS/nonmatch_patents_{value}.csv\"\n",
    "    df2_cleaned.to_stata(file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacd4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
